{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6bik4UgVu5y"
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from nltk.corpus import stopwords \r\n",
        "from collections import Counter\r\n",
        "import string\r\n",
        "import re\r\n",
        "import seaborn as sns\r\n",
        "from tqdm import tqdm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0s_CrS1XOr-",
        "outputId": "a9070a0e-fb88-41e4-a00e-b6b68fd2d0cc"
      },
      "source": [
        "import torch\r\n",
        "is_cuda = torch.cuda.is_available()\r\n",
        "\r\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\r\n",
        "if is_cuda:\r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print(\"GPU is available\")\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HFh4BQpnXSBO",
        "outputId": "9836fb84-6045-42ff-e2c4-35875da649bf"
      },
      "source": [
        "base_csv = 'agnews.csv'\r\n",
        "df = pd.read_csv(base_csv)\r\n",
        "df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class Index  ...                                        Description\n",
              "0            3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
              "1            3  ...  Reuters - Private investment firm Carlyle Grou...\n",
              "2            3  ...  Reuters - Soaring crude prices plus worries\\ab...\n",
              "3            3  ...  Reuters - Authorities have halted oil export\\f...\n",
              "4            3  ...  AFP - Tearaway world oil prices, toppling reco...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8rviHslXoVQ",
        "outputId": "cdb13ced-00cd-4925-8fab-e219b193a62a"
      },
      "source": [
        "X,y = df['Description'].values,df['Class Index'].values\r\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\r\n",
        "print(f'shape of train data is {x_train.shape}')\r\n",
        "print(f'shape of test data is {x_test.shape}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of train data is (90000,)\n",
            "shape of test data is (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9_S2WaGnXrSN",
        "outputId": "ae0705ff-e94a-424a-f01a-15e8a8926e1b"
      },
      "source": [
        "dd = pd.Series(y_train).value_counts()\r\n",
        "sns.barplot(x=np.array(['1','2','3','4']),y=dd.values)\r\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLCQMPdUXtwW"
      },
      "source": [
        "def preprocess_string(s):\r\n",
        "    # Remove all non-word characters (everything except numbers and letters)\r\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\r\n",
        "    # Replace all runs of whitespaces with no space\r\n",
        "    s = re.sub(r\"\\s+\", '', s)\r\n",
        "    # replace digits with no space\r\n",
        "    s = re.sub(r\"\\d\", '', s)\r\n",
        "\r\n",
        "    return s\r\n",
        "\r\n",
        "def tockenize(x_train,y_train,x_val,y_val):\r\n",
        "    word_list = []\r\n",
        "\r\n",
        "    stop_words = set(stopwords.words('english')) \r\n",
        "    for sent in x_train:\r\n",
        "        for word in sent.lower().split():\r\n",
        "            word = preprocess_string(word)\r\n",
        "            if word not in stop_words and word != '':\r\n",
        "                word_list.append(word)\r\n",
        "  \r\n",
        "    corpus = Counter(word_list)\r\n",
        "    # sorting on the basis of most common words\r\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\r\n",
        "    # creating a dict\r\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\r\n",
        "    \r\n",
        "    # tockenize\r\n",
        "    final_list_train,final_list_test = [],[]\r\n",
        "    for sent in x_train:\r\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \r\n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\r\n",
        "    for sent in x_val:\r\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \r\n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\r\n",
        "            \r\n",
        "    return np.array(final_list_train), np.array(y_train),np.array(final_list_test), np.array(y_val),onehot_dict"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mng2g6XxXxLO",
        "outputId": "ae4b477e-8ad4-4393-a1a2-38e25183915d"
      },
      "source": [
        "  >>> import nltk\r\n",
        "  >>> nltk.download('stopwords')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK535yPXXz5q",
        "outputId": "dc652c46-a9f4-4908-adac-262fe6614747"
      },
      "source": [
        "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwUVcQRZX5tv",
        "outputId": "6ca169da-3230-43ab-b8be-8c4ba0a7edd6"
      },
      "source": [
        "print(f'Length of vocabulary is {len(vocab)}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocabulary is 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "7IS9nr6jX68u",
        "outputId": "1a55e932-3ef1-4759-e362-1d207fab5d3c"
      },
      "source": [
        "rev_len = [len(i) for i in x_train]\r\n",
        "pd.Series(rev_len).hist()\r\n",
        "plt.show()\r\n",
        "pd.Series(rev_len).describe()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    90000.000000\n",
              "mean        10.095433\n",
              "std          4.271054\n",
              "min          0.000000\n",
              "25%          7.000000\n",
              "50%         10.000000\n",
              "75%         13.000000\n",
              "max         56.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPG4AjssX-Me"
      },
      "source": [
        "def padding_(sentences, seq_len):\r\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\r\n",
        "    for ii, review in enumerate(sentences):\r\n",
        "        if len(review) != 0:\r\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\r\n",
        "    return features"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7jdpG7PYBDB"
      },
      "source": [
        "#we have very less number of reviews with length > 500.\r\n",
        "#So we will consideronly those below it.\r\n",
        "x_train_pad = padding_(x_train,500)\r\n",
        "x_test_pad = padding_(x_test,500)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY3dpdDeYC36"
      },
      "source": [
        "# create Tensor datasets\r\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\r\n",
        "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\r\n",
        "\r\n",
        "# dataloaders\r\n",
        "batch_size = 50\r\n",
        "\r\n",
        "# make sure to SHUFFLE your data\r\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\r\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gREtrJ-YFre",
        "outputId": "13adecb3-4422-49ed-c6e9-f0643aea794a"
      },
      "source": [
        "# obtain one batch of training data\r\n",
        "dataiter = iter(train_loader)\r\n",
        "sample_x, sample_y = dataiter.next()\r\n",
        "\r\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\r\n",
        "print('Sample input: \\n', sample_x)\r\n",
        "print('Sample input: \\n', sample_y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 500])\n",
            "Sample input: \n",
            " tensor([[  0,   0,   0,  ..., 583, 679,  90],\n",
            "        [  0,   0,   0,  ..., 801, 835, 824],\n",
            "        [  0,   0,   0,  ..., 811,  18,  10],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  50, 384, 317],\n",
            "        [  0,   0,   0,  ..., 506,   1,   9],\n",
            "        [  0,   0,   0,  ..., 677, 956, 467]])\n",
            "Sample input: \n",
            " tensor([1, 1, 2, 3, 2, 4, 4, 1, 2, 2, 2, 4, 2, 4, 1, 1, 1, 3, 1, 4, 1, 4, 2, 3,\n",
            "        3, 4, 2, 3, 4, 3, 1, 1, 4, 3, 4, 2, 1, 3, 3, 3, 1, 1, 1, 1, 3, 4, 4, 2,\n",
            "        1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbMsjIRVYIh9"
      },
      "source": [
        "class SentimentRNN(nn.Module):\r\n",
        "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\r\n",
        "        super(SentimentRNN,self).__init__()\r\n",
        " \r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        " \r\n",
        "        self.no_layers = no_layers\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "    \r\n",
        "        # embedding and LSTM layers\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "        \r\n",
        "        #lstm\r\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\r\n",
        "                           num_layers=no_layers, batch_first=True)\r\n",
        "        \r\n",
        "        \r\n",
        "        # dropout layer\r\n",
        "        self.dropout = nn.Dropout(0.3)\r\n",
        "    \r\n",
        "        # linear and sigmoid layer\r\n",
        "        self.fc = nn.Linear(self.hidden_dim, output_dim)\r\n",
        "        self.sig = nn.Sigmoid()\r\n",
        "        \r\n",
        "    def forward(self,x,hidden):\r\n",
        "        batch_size = x.size(0)\r\n",
        "        # embeddings and lstm_out\r\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\r\n",
        "        #print(embeds.shape)  #[50, 500, 1000]\r\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\r\n",
        "        \r\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \r\n",
        "        \r\n",
        "        # dropout and fully connected layer\r\n",
        "        out = self.dropout(lstm_out)\r\n",
        "        out = self.fc(out)\r\n",
        "        \r\n",
        "        # sigmoid function\r\n",
        "        sig_out = self.sig(out)\r\n",
        "        \r\n",
        "        # reshape to be batch_size first\r\n",
        "        sig_out = sig_out.view(batch_size, -1)\r\n",
        "\r\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\r\n",
        "        \r\n",
        "        # return last sigmoid output and hidden state\r\n",
        "        return sig_out, hidden\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "        ''' Initializes hidden state '''\r\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\r\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\r\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\r\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\r\n",
        "        hidden = (h0,c0)\r\n",
        "        return hidden"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392Fa31wYM3y",
        "outputId": "fbb3af8e-5747-45e6-860e-dad256b3281d"
      },
      "source": [
        "no_layers = 4\r\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\r\n",
        "embedding_dim = 64\r\n",
        "output_dim = 1\r\n",
        "hidden_dim = 256\r\n",
        "\r\n",
        "\r\n",
        "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\r\n",
        "\r\n",
        "#moving to gpu\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "print(model)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(1001, 64)\n",
            "  (lstm): LSTM(64, 256, num_layers=4, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUbzeMsFYQ6C"
      },
      "source": [
        "# loss and optimization functions\r\n",
        "lr=0.001\r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "\r\n",
        "# function to predict accuracy\r\n",
        "def acc(pred,label):\r\n",
        "    pred = torch.round(pred.squeeze())\r\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NChXbWROYUKf"
      },
      "source": [
        "clip = 5\r\n",
        "epochs = 5\r\n",
        "valid_loss_min = np.Inf\r\n",
        "# train for some number of epochs\r\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\r\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "    train_losses = []\r\n",
        "    train_acc = 0.0\r\n",
        "    model.train()\r\n",
        "    # initialize hidden state \r\n",
        "    h = model.init_hidden(batch_size)\r\n",
        "    for inputs, labels in train_loader:\r\n",
        "        \r\n",
        "        inputs, labels = inputs.to(device), labels.to(device)   \r\n",
        "        # Creating new variables for the hidden state, otherwise\r\n",
        "        # we'd backprop through the entire training history\r\n",
        "        h = tuple([each.data for each in h])\r\n",
        "        \r\n",
        "        model.zero_grad()\r\n",
        "        output,h = model(inputs,h)\r\n",
        "        \r\n",
        "        # calculate the loss and perform backprop\r\n",
        "        loss = criterion(output.squeeze(), labels.float())\r\n",
        "        loss.backward()\r\n",
        "        train_losses.append(loss.item())\r\n",
        "        # calculating accuracy\r\n",
        "        accuracy = acc(output,labels)\r\n",
        "        train_acc += accuracy\r\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\r\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        optimizer.step()\r\n",
        " \r\n",
        "    \r\n",
        "        \r\n",
        "    val_h = model.init_hidden(batch_size)\r\n",
        "    val_losses = []\r\n",
        "    val_acc = 0.0\r\n",
        "    model.eval()\r\n",
        "    for inputs, labels in valid_loader:\r\n",
        "            val_h = tuple([each.data for each in val_h])\r\n",
        "\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "            output, val_h = model(inputs, val_h)\r\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\r\n",
        "\r\n",
        "            val_losses.append(val_loss.item())\r\n",
        "            \r\n",
        "            accuracy = acc(output,labels)\r\n",
        "            val_acc += accuracy\r\n",
        "            \r\n",
        "    epoch_train_loss = np.mean(train_losses)\r\n",
        "    epoch_val_loss = np.mean(val_losses)\r\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\r\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\r\n",
        "    epoch_tr_loss.append(epoch_train_loss)\r\n",
        "    epoch_vl_loss.append(epoch_val_loss)\r\n",
        "    epoch_tr_acc.append(epoch_train_acc)\r\n",
        "    epoch_vl_acc.append(epoch_val_acc)\r\n",
        "    print(f'Epoch {epoch+1}') \r\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\r\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\r\n",
        "    if epoch_val_loss <= valid_loss_min:\r\n",
        "        #torch.save(model.state_dict(), '../working/state_dict.pt')\r\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\r\n",
        "        valid_loss_min = epoch_val_loss\r\n",
        "    print(25*'==')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8pL9RkE83yh"
      },
      "source": [
        "fig = plt.figure(figsize = (20, 6))\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "plt.plot(epoch_tr_acc, label='Train Acc')\r\n",
        "plt.plot(epoch_vl_acc, label='Validation Acc')\r\n",
        "plt.title(\"Accuracy\")\r\n",
        "plt.legend()\r\n",
        "plt.grid()\r\n",
        "    \r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.plot(epoch_tr_loss, label='Train loss')\r\n",
        "plt.plot(epoch_vl_loss, label='Validation loss')\r\n",
        "plt.title(\"Loss\")\r\n",
        "plt.legend()\r\n",
        "plt.grid()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qbKm1rvi-2d"
      },
      "source": [
        "def predict_text(text):\r\n",
        "        word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \r\n",
        "                         if preprocess_string(word) in vocab.keys()])\r\n",
        "        word_seq = np.expand_dims(word_seq,axis=0)\r\n",
        "        pad =  torch.from_numpy(padding_(word_seq,500))\r\n",
        "        inputs = pad.to(device)\r\n",
        "        batch_size = 1\r\n",
        "        h = model.init_hidden(batch_size)\r\n",
        "        h = tuple([each.data for each in h])\r\n",
        "        output, h = model(inputs, h)\r\n",
        "        return(output.item())"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEaiGnRojGpf",
        "outputId": "ffc00a2d-b380-433f-da93-9b8379b8b759"
      },
      "source": [
        "index = 30\r\n",
        "print(df['Title'][index])\r\n",
        "print('='*70)\r\n",
        "print(f'Actual sentiment is  : {df[\"Class Index\"][index]}')\r\n",
        "print('='*70)\r\n",
        "pro = predict_text(df['Title'][index])\r\n",
        "status = \"1\" if pro > 0.5 else \"2\"\r\n",
        "pro = (1 - pro) if status == \"negative\" else pro\r\n",
        "print(f'Predicted sentiment is {status} with a probability of {pro}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Japan nuclear firm shuts plants\n",
            "======================================================================\n",
            "Actual sentiment is  : 3\n",
            "======================================================================\n",
            "Predicted sentiment is 1 with a probability of 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7nZuTnzj33K",
        "outputId": "9069ac9e-3eba-41ba-9fcc-39d518906a9e"
      },
      "source": [
        "index = 56\r\n",
        "print(df['Title'][index])\r\n",
        "print('='*70)\r\n",
        "print(f'Actual sentiment is  : {df[\"Class Index\"][index]}')\r\n",
        "print('='*70)\r\n",
        "pro = predict_text(df['Title'][index])\r\n",
        "status = \"1\" if pro > 0.5 else \"2\"\r\n",
        "pro = (1 - pro) if status == \"negative\" else pro\r\n",
        "print(f'Predicted sentiment is {status} with a probability of {pro}')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stoking the Steamroller\n",
            "======================================================================\n",
            "Actual sentiment is  : 3\n",
            "======================================================================\n",
            "Predicted sentiment is 1 with a probability of 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}